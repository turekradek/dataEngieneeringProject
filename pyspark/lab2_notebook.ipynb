{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sales order data exploration\n",
    "Use the code in this notebook to explore sales order data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, desc\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from delta.tables import *\n",
    "from pyspark.sql.functions import col, dayofmonth, month, year, date_format\n",
    "import findspark\n",
    "import zipfile \n",
    "import os\n",
    "from pyspark.sql.functions import when, lit, col, current_timestamp, input_file_name\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "findspark.init()\n",
    "spark = SparkSession.builder.appName(\"sparksql\").getOrCreate()\n",
    "%load_ext sparksql_magic\n",
    "%config SparkSql.max_num_rows=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "datafabric_baseurl = \"/home/radek/git_projekty/sparkTraining/datafabrictraining\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"/home/radek/git_projekty/sparkTraining/orders/2019.csv\")\n",
    "# df = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"abfss://420c196f-1dff-4a10-960e-cb2b82bac5fb@onelake.dfs.fabric.microsoft.com/041002d6-72a1-41a6-8711-db0afa5e63b6/Files/orders/2019.csv\")\n",
    "# df now is a Spark DataFrame containing CSV data from \"abfss://420c196f-1dff-4a10-960e-cb2b82bac5fb@onelake.dfs.fabric.microsoft.com/041002d6-72a1-41a6-8711-db0afa5e63b6/Files/orders/2019.csv\".\n",
    "display(df)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "orderSchema = StructType([\n",
    "    StructField(\"SalesOrderNumber\", StringType()),\n",
    "    StructField(\"SalesOrderLineNumber\", IntegerType()),\n",
    "    StructField(\"OrderDate\", DateType()),\n",
    "    StructField(\"CustomerName\", StringType()),\n",
    "    StructField(\"Email\", StringType()),\n",
    "    StructField(\"Item\", StringType()),\n",
    "    StructField(\"Quantity\", IntegerType()),\n",
    "    StructField(\"UnitPrice\", FloatType()),\n",
    "    StructField(\"Tax\", FloatType())\n",
    "    ])\n",
    "\n",
    "df = spark.read.format(\"csv\").schema(orderSchema).load(\"/home/radek/git_projekty/sparkTraining/orders/2019.csv\")\n",
    "display(df)\n",
    "df.show(3)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
